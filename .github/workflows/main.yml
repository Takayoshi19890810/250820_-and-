name: Daily News Scraper & Aggregator

on:
  schedule:
    # æ¯æ—¥ JST 15:10 ã«å®Ÿè¡Œï¼ˆUTC 06:10ï¼‰
    - cron: '10 6 * * *'
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: ğŸ“¦ Check out repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ§° Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg ca-certificates
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt -f install -y

      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: â–¶ï¸ Run scraper & aggregator
        env:
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          # å¿…è¦ã«å¿œã˜ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰ãˆãŸã„ã¨ãã¯Secrets/Variablesã§ä¸Šæ›¸ãã—ã¦ãã ã•ã„
          NEWS_KEYWORD: ${{ vars.NEWS_KEYWORD || 'æ—¥ç”£' }}
          SPREADSHEET_ID: ${{ vars.SPREADSHEET_ID || '1RglATeTbLU1SqlfXnNToJqhXLdNoHCdePldioKDQgU8' }}
        run: |
          python main.py
