name: Daily News Scraper & Aggregator

on:
  schedule:
    # æ¯æ—¥ JST 15:10 ã«å®Ÿè¡Œï¼ˆUTC 06:10ï¼‰
    - cron: '10 6 * * *'
  workflow_dispatch:

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: ğŸ“¦ Check out repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: ğŸ§° Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg ca-certificates
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt -f install -y
          google-chrome --version

      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: â–¶ï¸ Run scraper & aggregator
        env:
          # å¿…é ˆï¼šã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’Secretsã«ä¿å­˜ã—ã€ã“ã“ã§å‚ç…§
          GCP_SERVICE_ACCOUNT_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          # ä»»æ„ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‚æœªè¨­å®šãªã‚‰ 'æ—¥ç”£'
          NEWS_KEYWORD: ${{ vars.NEWS_KEYWORD || 'æ—¥ç”£' }}
          # æœ€å„ªå…ˆã§æ­£ã—ã„å‡ºåŠ›å…ˆã«å›ºå®š
          SPREADSHEET_ID: 1Vs4Cx8QPN4H2NOgtwaviOCe8zBTpUNDgJjqkHr51IZE
        run: |
          python main.py
